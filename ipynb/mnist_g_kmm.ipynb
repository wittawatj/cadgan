{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to test kernel moment matching with a GAN generator. Data = MNIST. \n",
    "For a more convenient test on MNIST, see this Colab notebook: https://colab.research.google.com/drive/1gH2naGOwxYNz6OGDydc9SPz7AHJlc5u7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadgan\n",
    "import cadgan.kernel as kernel\n",
    "import cadgan.glo as glo\n",
    "import cadgan.main as main\n",
    "import cadgan.net.net as net\n",
    "import cadgan.gen as gen\n",
    "import cadgan.plot as plot\n",
    "import cadgan.util as util\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "tensor_type = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "torch.set_default_tensor_type(tensor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "import cadgan.gan.mnist.classify as mnist_classify\n",
    "from cadgan.gan.mnist.classify import MnistClassifier\n",
    "\n",
    "\n",
    "classifier = mnist_classify.MnistClassifier(load=True)\n",
    "classifier = classifier.eval()\n",
    "classifier = classifier.to(device)\n",
    "# classifier = classifier.cuda()\n",
    "\n",
    "def extractor_maker(classifier):\n",
    "    \"\"\"\n",
    "    Constructor and return a CNN-based feature extractor of type \n",
    "    cadgan.net.net.ModuleAdapter\n",
    "    \"\"\"    \n",
    "    def extractor(imgs):\n",
    "        \"\"\"\n",
    "        Feature extractor. This function should be as self-contained \n",
    "        (in its own lexical scope ) as possible since we will serialize\n",
    "        it.\n",
    "        \"\"\"\n",
    "        import torch.nn.functional as F\n",
    "    #     return classifier.features(imgs)\n",
    "        x = imgs\n",
    "        x = F.relu(F.max_pool2d(classifier.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(classifier.conv2(x), 2))\n",
    "#         x = x.view(imgs.shape[0], -1)\n",
    "        \n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(classifier.fc1(x))\n",
    "#         x = classifier.fc2(x)\n",
    "        x = x.view(imgs.shape[0], -1)\n",
    "        \n",
    "    #     x = x.view(-1, 10*12*12)\n",
    "    #     x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "    adapter = net.ModuleAdapter(extractor)\n",
    "    return adapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an extractor\n",
    "cnn_extractor = extractor_maker(classifier)\n",
    "extractor = cnn_extractor\n",
    "\n",
    "# Save the extractor as an object of type cadgan.net.net.ModuleAdapter\n",
    "#extractor_fname = 'mnist_l2_cnn.pt'\n",
    "#extractor_fpath = glo.prob_model_folder('mnist_cnn', extractor_fname)\n",
    "#print('Saving the extractor to', extractor_fpath)\n",
    "#extractor.save(extractor_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "mnist_folder = glo.data_file('mnist')\n",
    "mnist_dataset = torchvision.datasets.MNIST(mnist_folder, train=False, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "#                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xy = mnist_dataset[92]\n",
    "x = xy[0]\n",
    "x = x.unsqueeze(0)\n",
    "x = x.to(device)\n",
    "\n",
    "# plot\n",
    "xnp = x.cpu().numpy()\n",
    "np.transpose(xy[0].numpy(), (1, 2, 0))\n",
    "xnp = xnp.squeeze()\n",
    "plt.imshow(xnp, cmap=plt.cm.Greys_r)\n",
    "print('features: ', classifier(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A generator for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cadgan.gan.mnist.dcgan as mnist_dcgan\n",
    "\n",
    "# load a model\n",
    "g = mnist_dcgan.Generator(load=True)\n",
    "g = g.eval().to(device)\n",
    "\n",
    "# transform the output range of g to (0,1)\n",
    "g = nn.Sequential(g, gen.LinearRangeTransform(from_range=(-1, 1), to_range=(0,1)))\n",
    "\n",
    "\n",
    "latent_dim = 100\n",
    "def f_noise_creator(latent_dim, device=device, tensor_type=tensor_type):\n",
    "    return lambda n: torch.randn(n, latent_dim).to(device).type(tensor_type)\n",
    "f_noise = f_noise_creator(latent_dim=latent_dim, device=device, tensor_type=tensor_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the generator as type gen.PTNoiseTransformer\n",
    "out_shape = g(f_noise(1)).shape[1:]\n",
    "in_out_shapes = (latent_dim, out_shape)\n",
    "g_ptnt = gen.PTNoiseTransformerAdapter(g, f_noise, in_out_shapes, tensor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show samples from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial points in the latent space\n",
    "# n_sample = 2*2**3\n",
    "n_sample = 5*6\n",
    "# noise vectors\n",
    "Z = f_noise(n_sample)\n",
    "Z = Z.to(device)\n",
    "\n",
    "Z.requires_grad = True\n",
    "Y0 = g(Z)\n",
    "\n",
    "# plot the initial points in the image space\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=6)\n",
    "plt.axis('off')\n",
    "plt.savefig('dcgan_samples.pdf', bboxes_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize points jointly to minimize the moment matching loss\n",
    "\n",
    "With a GAN generator. Optimize in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sample_by_labels(data, label_counts):\n",
    "    \"\"\"\n",
    "    data: a dataset such that data[i][0] is a point, and data[i][1] is an integer label.\n",
    "    label_counts: a list of tuples of two values (A, B), where A is a label, and B is the count.\n",
    "    \"\"\"\n",
    "    list_selected = []\n",
    "    labels = np.array([data[i][1] for i in range(len(data))])\n",
    "    for label, count in label_counts:\n",
    "        inds = np.where(labels==label)[0]\n",
    "        homo_data = [data[i][0] for i in inds[:count]]\n",
    "        list_selected.extend(homo_data)\n",
    "    # stack all\n",
    "    selected = torch.stack(list_selected)\n",
    "    return selected\n",
    "\n",
    "# The set of points representing the mean embedding that we want to sample from.\n",
    "# As an example, we will construct this manually.\n",
    "# img_indices = [2, 5, 9, 12, 14, 16, 17, 20, 26, 29, 31, 34, 36, 37]\n",
    "# img_indices = [2, 5, 14, 29, 31, 37, 39, 40, 46, 57]\n",
    "# img_indices = [3, 5]\n",
    "# X = torch.stack([mnist_dataset[i][0] for i in img_indices], dim=0)\n",
    "\n",
    "label_counts = [(2, 2), (9, 2)]\n",
    "# label_counts = [(4, 1)]\n",
    "# label_counts = [(1, 2), (7, 1)]\n",
    "# label_counts = [(6, 1), (9, 2)]\n",
    "# label_counts = [(5, 2), (7, 1)]\n",
    "# label_counts = [(3, 2)]\n",
    "# label_counts = [(3, 1), (8, 1)]\n",
    "# label_counts = [(6, 2), (3, 1)]\n",
    "# label_counts = [(5, 1)]\n",
    "# label_counts = [(1,1), (2,1), (3,1), (4,1)]\n",
    "# label_counts = [(i, 5) for i in range(10)]\n",
    "# label_counts = [(0, 6)]\n",
    "X = sample_by_labels(mnist_dataset, label_counts)\n",
    "X = X.to(device)\n",
    "n = X.shape[0]\n",
    "\n",
    "# A vector of weights for all the points in X\n",
    "weights = torch.ones(n)/float(n)\n",
    "weights = weights.to(device)\n",
    "plot.show_torch_imgs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.show_torch_imgs(torch.mean(X, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "cond_summ = '+'.join('{}_{}'.format(d, c) for d,c in label_counts)\n",
    "plt.savefig('mnist-{}-mean.pdf'.format(cond_summ), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initial points in the latent space\n",
    "# n_sample = 2*2**3\n",
    "n_sample = 3*1\n",
    "# noise vectors\n",
    "Z = f_noise(n_sample)\n",
    "Z = Z.to(device)\n",
    "\n",
    "Z.requires_grad = True\n",
    "Y0 = g(Z)\n",
    "\n",
    "# plot the initial points in the image space\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadgan.net.extractor as exmod\n",
    "\n",
    "extractor_names = ['cnn', 'pixel']\n",
    "extractors = [cnn_extractor, exmod.Identity(flatten=True)]\n",
    "\n",
    "# Choose here\n",
    "extractor_choice = 0\n",
    "extractor = extractors[extractor_choice]\n",
    "print('Using extractor: {}'.format(extractor_names[extractor_choice]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-extract the features of X. Fixed throughout the optimization\n",
    "with torch.no_grad():\n",
    "    FX = extractor(X)\n",
    "    \n",
    "# optimizer = torch.optim.SGD([Y], lr=5e-3)\n",
    "# optimizer = torch.optim.RMSprop([Z], lr=5e-2)\n",
    "optimizer = torch.optim.Adam([Z], lr=5e-2)\n",
    "\n",
    "# kernel on the extracted features\n",
    "# med = util.meddistance(FX.cpu().numpy(), subsample=1000)\n",
    "# k = kernel.PTKGauss(sigma2=med**2)\n",
    "# k = kernel.PTKPoly(c=1e-1, d=2)\n",
    "k = kernel.PTKIMQ(b=-0.5, c=10)\n",
    "# k = kernel.PTKLinear()\n",
    "\n",
    "# kernel on the latent noise vectors\n",
    "# k = kernel.PTKFuncCompose(kgauss, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# optimization\n",
    "n_iter = 1000\n",
    "losses = []\n",
    "sample_interval = 200\n",
    "# avgpool = torch.nn.AvgPool2d(5, stride=1, padding=0)\n",
    "\n",
    "mean_KFX = torch.mean(k.eval(FX, FX))\n",
    "for t in range(n_iter):\n",
    "    # need to resize since Mnist uses 28x28. The generator generates 32x32\n",
    "    gens = g(Z)\n",
    "#     resized = torch.stack([resize_gen_img(I) for I in gens], 0)\n",
    "#     resized = avgpool(gens)\n",
    "#     plot.show_torch_imgs(resized)\n",
    "    F_gz = extractor(gens)\n",
    "    KF_gz = k.eval(F_gz, F_gz)\n",
    "#     print(KF_gz)\n",
    "    \n",
    "    # encourage the latent noise vectors to concentrate around 0\n",
    "#     Z_reg = 1e-6*torch.mean(torch.sum(Z**2, 1))\n",
    "    \n",
    "    Z_reg = 0\n",
    "#     Z_reg = -1e-5*torch.mean(torch.log(3.5**2-Z**2))\n",
    "    \n",
    "    loss = torch.mean(KF_gz)  - 2.0*torch.mean(k.eval(F_gz, FX).mv(weights)) + mean_KFX  + Z_reg\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    Z.data.clamp_(-3.5, 3.5)\n",
    "    # compute the gradients\n",
    "    loss.backward(retain_graph=True)\n",
    "    # updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    #--------- plots the generated images ----\n",
    "    if t%sample_interval==0:\n",
    "        with torch.no_grad():\n",
    "            gen_show = g(Z.detach().clone())\n",
    "#             gen = Z.detach().clone()\n",
    "#             gen = Z.grad.detach().clone()\n",
    "            plot.show_torch_imgs(gen_show, normalize=True)\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.show_torch_imgs(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_summary_key():\n",
    "    \"\"\"\n",
    "    Return a key (e.g., for file naming) that summarizes roughly the hyperparameters chosen.\n",
    "    \"\"\"\n",
    "    ext_name = extractor_names[extractor_choice]\n",
    "    kernel_name = k.__class__.__name__\n",
    "    cond = '+'.join('{}_{}'.format(d, c) for d,c in label_counts)\n",
    "    s = 'mnist-{}-{}-{}-n{}'.format(cond,ext_name, kernel_name, n_sample)\n",
    "    return s\n",
    "\n",
    "prefix_fname = prob_summary_key()\n",
    "print(prefix_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input points\n",
    "plot.show_torch_imgs(X, nrow=2)\n",
    "# plt.title('Input')\n",
    "plt.axis('off')\n",
    "plt.savefig('{}-cond.pdf'.format(prefix_fname), bbox_inches='tight')\n",
    "\n",
    "plot.show_torch_imgs(Y0.detach(), nrow=4)\n",
    "# plt.title('Initialized')\n",
    "plt.axis('off')\n",
    "plt.savefig('{}-init.pdf'.format(prefix_fname), bbox_inches='tight')\n",
    "\n",
    "plot.show_torch_imgs(gen_show, nrow=4)\n",
    "# plt.title('Output')\n",
    "plt.axis('off')\n",
    "plt.savefig('{}-out.pdf'.format(prefix_fname), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('Optimization iteration')\n",
    "plt.ylabel('MMD loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.imshow(Z.cpu().detach().numpy())\n",
    "plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
